{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Programming PyTorch for Deep Learning\n",
    "### Ian Pointer (O'Reilly)\n",
    "### Notes and tests\n",
    "\n",
    "This books assumes a working CUDA installation. Let's hope for the best...\n",
    "\n",
    "## Chapter 1. Getting started with PyTorch\n",
    "### Tensors\n",
    "A tensor is both a container for numbers (like a vector or matrix) but also represents sets of rules defining transformations\n",
    "between tensors that produce new tensors. Tensors have ranks that represent their dimensional space. Tensors with PyTorch\n",
    "support fetching and changing elements using the standard Python indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor(3)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch, torchvision, numpy, pandas\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(x)\n",
    "print(x[0][-1])  # fetch the last element of the first dimension\n",
    "x[0][0] = 10  # change the value of the first element of the first dimension\n",
    "\n",
    "# There are multiple functions that can create tensors, like torch.zeros(), torch.ones(), torch.rand()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tensor operations\n",
    "There are a lot.\n",
    "For instance, we can find the maximum value in a tensor like this:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[0.4608, 0.0096],\n",
      "        [0.7883, 0.7824]])\n",
      "tensor(0.7883) tensor(2) 0.7883459329605103\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "print(x)\n",
    "print(x.max(), x.argmax(), x.max().item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are multiple types of tensors, for instance ```LongTensors``` or ```FloatTensors```. We can convert back and forth \n",
    "using the ```.to()``` method."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "torch.LongTensor\n",
      "torch.FloatTensor\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "long_tensor = torch.tensor([[0, 0, 1], [1, 1, 1], [0, 0, 0]])\n",
    "print(long_tensor.type())\n",
    "float_tensor = long_tensor.to(dtype=torch.float32)\n",
    "print(float_tensor.type())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sometimes it may be useful to make use of **in-place** operations, as it will save memory by avoiding copying the tensor.\n",
    "In-place functions are post-fixed with a \"_\" symbol."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[0.2643, 0.8364],\n",
      "        [0.1725, 0.3988]])\n",
      "tensor([[0.2643, 0.8364],\n",
      "        [0.1725, 0.3988]])\n",
      "tensor([[-1.9199, -0.2577],\n",
      "        [-2.5355, -1.3263]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "print(x)\n",
    "x.log2()\n",
    "print(x)\n",
    "x.log2_()  # Only this in-place operation will change the original tensor (x)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reshaping\n",
    "An important task is to reshape tensors. We can use ```torch.view()``` or ```torch.reshape()```. The main difference is\n",
    "that ```torch.view()``` operates as a view of the original tensor, so if the underlying data is changed, the view will also\n",
    "change, whereas this does not happen with ```torch.reshape()```. Another difference is that ```torch.view()``` requires\n",
    "that the tensors/views being operated on **are contiguous**, that is, they need to share the same memory blocks they would\n",
    "occupy if a new tensor of the desired shape was created ex-novo. In this case, de-fragment stuff with ```torch.contiguous()```\n",
    "before the ```torch.view()``` operations.\n",
    "#### Rearranging tensor dimensions\n",
    "Another important operation is to re-arrange the dimensions in tensors. For instance, usually RGB image data is organized\n",
    "in ```[width, height, channel]``` but usually PyTorch likes this data as ```[channel, width, height]```. We can use the\n",
    "```torch.permute()``` method by supplying the new order of the dimensions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "torch.Size([3, 640, 480])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = torch.rand(640, 480, 3)\n",
    "x_rearranged = x.permute(2, 0, 1)  # put the last dimension (RGB) as the first one.\n",
    "print(x_rearranged.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tensor broadcasting\n",
    "Tensor broadcasting is an approach that allows to perform operations between a tensor and a smaller tensor. It is possible\n",
    "to broadcast across two tensors if, starting from their trailing dimensions:\n",
    "* The two dimensions are equal\n",
    "* One of the dimensions is 1\n",
    "\n",
    "The book doesn't really expand much on this, but my understanding is that, as long as the limitations above are respected,\n",
    "it can automatically pad the smaller tensor to have the same size as the larger one, and then operate.\n",
    "## Chapter 2. Image Classification with PyTorch\n",
    "Now we are going to incrementally build a simple neural network with the task of performing image classification between\n",
    "fishes and cats. First of all, we need data. The ```download.py``` script, included in the book's GitHub, supposedly\n",
    "downloads a subset of ImageNet data, already separated in 3 datasets (**training**, **test** and **validation**) and for\n",
    "each of these datasets, the images are already divided into fish or cat categories. The script, unfortunately, seems to \n",
    "have failed for several images, and several other had not been downloaded properly, so let's see how it goes. I guess it's\n",
    "a really real-world example...\n",
    "### PyTorch and Data Loaders\n",
    "Formally, a PyTorch ```dataset``` is a Python class that allows us to get at the data we're supplying to the neural network. \n",
    "A ```data loader``` is what actually feeds data from the dataset into the network. \n",
    "A dataset is defined as a class that defines at least a ```.__getitem__(self, index)``` method, and a ```.__len__(self)```\n",
    "method. These two methods provide a way of retrieving elements from the data, in ```(label, tensor)``` pairs, and a way\n",
    "of obtaining the size of the dataset, respectively.\n",
    "### Building a training dataset\n",
    "The ```torchvision``` module provide several convenience function to deal with image dataset, such as the\n",
    "```ImageFolder``` class, which will greatly simplify dealing with image data, as long as the images are contained in a \n",
    "directory structure where each directory is a label (i.e. ```./train/cat/```, ```./train/fish/``` etc).\n",
    "\n",
    "For our purposes, this will be enough:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_data_path = \"./book_examples/train/\"\n",
    "\n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path, transform=my_transforms)\n",
    "\n",
    "val_data_path = \"./book_examples/val/\"\n",
    "val_data = torchvision.datasets.ImageFolder(root=val_data_path, transform=my_transforms)\n",
    "\n",
    "test_data_path = \"./book_examples/test/\"\n",
    "test_data = torchvision.datasets.ImageFolder(root=test_data_path, transform=my_transforms)\n",
    "\n",
    "my_batch_size = 64\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=my_batch_size)\n",
    "val_data_loader = data.DataLoader(val_data, batch_size=my_batch_size)\n",
    "test_data_loader = data.DataLoader(test_data, batch_size=my_batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that set ```datasets``` (and pertinent transforms) and ```dataloaders```, it's time to create the actual neural \n",
    "network!\n",
    "### Creating a network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "True\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Had to readjust several variables/imports that are not mentioned in the book examples. Cross-referencing with the official\n",
    "# 60-min tutorial helps a lot.\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(12288, 84)\n",
    "        self.fc2 = nn.Linear(84, 50)\n",
    "        self.fc3 = nn.Linear(50, 2)\n",
    "    \n",
    "    def forward(self,x ):\n",
    "        x = x.view(-1, 12288)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "simplenet = SimpleNet()\n",
    "\n",
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}