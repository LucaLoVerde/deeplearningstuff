{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Chapter 5. Advanced Computer Vision\n",
    "### Transfer learning\n",
    "We are going to try and re-purpose a pre-trained ImageNet nn on the CIFAR-10 dataset. We'll be using pytorch to show two\n",
    "different techniques, **feature extraction** and **fine tuning**.\n",
    "#### Feature extraction\n",
    "Feature extraction involves modifying the final layer of the existing net to accommodate the new task. Every weight of\n",
    "the network, except for the final, modified layer, are locked and will not change during the training procedure. This is \n",
    "shown below in the ```t1_feature_extractor()``` function.\n",
    "\n",
    "#### Fine tuning\n",
    "Fine tuning involves modifying the final layer of the existing net to accommodate the new task and then training the whole\n",
    "network, starting from the pre-trained weights. This is shown below in the ```t1_fine_tuning()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "C:\\Users\\Luca\\PycharmProjects\\deeplearningstuff\\Python_deep_learning_bk\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "********** BEGINNING FEATURE EXTRACTION PROCEDURE **********\n",
      "\n",
      "Epoch 1/5\n",
      "train loss: 1.0433; accuracy: 0.6446\n",
      "test loss: 0.8522; accuracy: 0.7046\n",
      "Epoch 2/5\n",
      "train loss: 0.8525; accuracy: 0.7029\n",
      "test loss: 0.8256; accuracy: 0.7110\n",
      "Epoch 3/5\n",
      "train loss: 0.8311; accuracy: 0.7100\n",
      "test loss: 0.8349; accuracy: 0.7046\n",
      "Epoch 4/5\n",
      "train loss: 0.8193; accuracy: 0.7124\n",
      "test loss: 0.8167; accuracy: 0.7152\n",
      "Epoch 5/5\n",
      "train loss: 0.8171; accuracy: 0.7152\n",
      "test loss: 0.7839; accuracy: 0.7223\n",
      "\n",
      "********** FEATURE EXTRATION PROCEDURE COMPLETED **********\n",
      "\n",
      "\n",
      "********** BEGINNING FINE TUNING PROCEDURE **********\n",
      "\n",
      "epoch: 1/5\n",
      "train loss: 0.8025; accuracy: 0.7194\n",
      "test loss: 0.7358; accuracy: 0.7384\n",
      "epoch: 2/5\n",
      "train loss: 0.5268; accuracy: 0.8188\n",
      "test loss: 0.5423; accuracy: 0.8189\n",
      "epoch: 3/5\n",
      "train loss: 0.4305; accuracy: 0.8508\n",
      "test loss: 0.4316; accuracy: 0.8576\n",
      "epoch: 4/5\n",
      "train loss: 0.3656; accuracy: 0.8729\n",
      "test loss: 0.3813; accuracy: 0.8661\n",
      "epoch: 5/5\n",
      "train loss: 0.3209; accuracy: 0.8888\n",
      "test loss: 0.3757; accuracy: 0.8716\n",
      "\n",
      "********** FINE TUNING PROCEDURE COMPLETED **********\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO: comment everything\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import os\n",
    "print(os.getcwd())\n",
    "batch_size = 50\n",
    "# training data transformation: the ImageNet implementation accepts 224x224 pixels inputs, whereas CIFAR-10 contains 32x32\n",
    "# images. Up-sample the images to match what the network wants, do minor augmentations, normalize the dataset to the average\n",
    "# and standard deviation of the ImageNet, because that is what the network expects.\n",
    "train_data_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# prepare training dataset\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_data_transform)\n",
    "\n",
    "from torch.utils.data.dataloader import  DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "val_data_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=val_data_transform)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model: nn.Module, loss_function: nn.CrossEntropyLoss, optimizer: torch.optim.Adam, data_loader: torch.utils.data.DataLoader):\n",
    "    \"\"\"\n",
    "    Training function for our model.\n",
    "    :param model: \n",
    "    :type model: nn.Module\n",
    "    :param loss_function: \n",
    "    :type loss_function: nn.CrossEntropyLoss\n",
    "    :param optimizer: \n",
    "    :type optimizer: torch.optim.Adam\n",
    "    :param data_loader: \n",
    "    :type data_loader: torch.utils.data.DataLoader\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    current_loss = 0.0\n",
    "    current_acc = 0.0\n",
    "    \n",
    "    # iterate\n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        current_loss += loss.item() * inputs.size(0)\n",
    "        hits = predictions == labels.data\n",
    "        current_acc += torch.sum(hits)\n",
    "        \n",
    "    total_loss = current_loss / len(data_loader.dataset)\n",
    "    total_acc = current_acc / len(data_loader.dataset)\n",
    "    \n",
    "    print('train loss: {:.4f}; accuracy: {:.4f}'.format(total_loss, total_acc))\n",
    "    \n",
    "    \n",
    "def test_model(model: nn.Module, loss_function: nn.CrossEntropyLoss, data_loader: torch.utils.data.DataLoader):\n",
    "    \"\"\"\n",
    "    Evaluation function for our model.\n",
    "    :param model: \n",
    "    :type model: nn.Module\n",
    "    :param loss_function: \n",
    "    :type loss_function: nn.CrossEntropyLoss\n",
    "    :param data_loader: \n",
    "    :type data_loader: torch.utils.data.DataLoader\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    current_loss = 0.0\n",
    "    current_acc = 0.0\n",
    "    \n",
    "    # iterate\n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            \n",
    "        current_loss += loss.item() * inputs.size(0)\n",
    "        hits = predictions == labels.data\n",
    "        current_acc += torch.sum(hits)\n",
    "        \n",
    "    total_loss = current_loss / len(data_loader.dataset)\n",
    "    total_acc = current_acc / len(data_loader.dataset)\n",
    "    print('test loss: {:.4f}; accuracy: {:.4f}'.format(total_loss, total_acc))\n",
    "    \n",
    "    \n",
    "def t1_feature_extractor(epochs: int = 3):\n",
    "    \"\"\"\n",
    "    Function that performs feature extraction to adapt the ImageNet network to the CIFAR-10 data and task. Only the new\n",
    "    final layer will be trained, while the rest of the network's weights are kept as they were.\n",
    "    :param epochs: Number of epochs to retrain our network.\n",
    "    :type epochs: int\n",
    "    \"\"\"\n",
    "    print('\\n********** BEGINNING FEATURE EXTRACTION PROCEDURE **********\\n')\n",
    "    model: nn.Module = torchvision.models.resnet18(pretrained=True)\n",
    "    \n",
    "    # Before modifying the final layer of the network, lock the rest of the network's weights\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # take the number of input features of the (old) final network layer\n",
    "    num_features = model.fc.in_features\n",
    "    # substitute the final layer with a new fully-connected layer with outputs matching CIFAR-10 classes\n",
    "    model.fc = nn.Linear(num_features, 10)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.Adam(model.fc.parameters())\n",
    "    \n",
    "    # training loop. this will only work on the final layer, since all the other layers have their autograd disabled\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
    "        \n",
    "        train_model(model, loss_function, optimizer, train_loader)\n",
    "        test_model(model, loss_function, val_loader)\n",
    "    \n",
    "    print('\\n********** FEATURE EXTRACTION PROCEDURE COMPLETED **********\\n')\n",
    "    \n",
    "    \n",
    "def t1_fine_tuning(epochs: int = 3):\n",
    "    \"\"\"\n",
    "    Function to perform fine tuning of the ImageNet to adapt it to the CIFAR-10 data and task. We will change the final\n",
    "    layer to reflect the new task, like in the feature extraction approach, but the rest of the network will be kept free\n",
    "    to adapt as well, building upon the old ImageNet training.\n",
    "    :param epochs: Number of epochs to retrain our network.\n",
    "    :type epochs: int\n",
    "    \"\"\"\n",
    "    print('\\n********** BEGINNING FINE TUNING PROCEDURE **********\\n')\n",
    "    model: nn.Module = models.resnet18(pretrained=True)\n",
    "    \n",
    "    # modify the final layer to be a fully-connected layer reflecting the CIFAR-10 task (10 outputs for the 10 classes)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 10)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    # training loop. in this case, the whole network can adapt to the new data\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch: {}/{}'.format(epoch + 1, epochs))\n",
    "        \n",
    "        train_model(model, loss_function, optimizer, train_loader)\n",
    "        test_model(model, loss_function, val_loader)\n",
    "        \n",
    "    print('\\n********** FINE TUNING PROCEDURE COMPLETED **********\\n')\n",
    "\n",
    "# EXECUTE\n",
    "t1_feature_extractor(5)\n",
    "t1_fine_tuning(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "pag 125"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}