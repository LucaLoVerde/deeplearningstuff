{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# pyTorch tutorials\n",
    "Taken from the official website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Essentials\n",
    "### Creating empty tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.3314, 0.6105, 0.1927],\n",
      "        [0.6066, 0.6493, 0.7359],\n",
      "        [0.7485, 0.2916, 0.3296],\n",
      "        [0.4770, 0.6908, 0.0363],\n",
      "        [0.7803, 0.8376, 0.9116]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "vuoto1 = torch.empty(5, 3)  # creates a 5-by-3 empty tensor\n",
    "print(vuoto1)\n",
    "\n",
    "random1 = torch.rand(5, 3)  # creates a 5-by-3 random tensor\n",
    "print(random1)\n",
    "\n",
    "zeros1 = torch.zeros(10, 2)  # creates a 10-by-2 zeroed tensor\n",
    "print(zeros1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Constructing a tensor from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([10.0000, 20.3000,  2.0000])\n",
      "tensor([10, 20,  2])\n",
      "tensor([10.0000, 20.3000,  2.0000], dtype=torch.float64)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# To construct a tensor from data, we can do:\n",
    "from_data1 = torch.tensor([10, 20.3, 2])\n",
    "print(from_data1)\n",
    "\n",
    "# We can specify the type of data we want\n",
    "from_data2 = torch.tensor([10, 20.3, 2], dtype=torch.long)\n",
    "print(from_data2)\n",
    "\n",
    "from_data3 = torch.tensor([10, 20.3, 2], dtype=torch.double)\n",
    "print(from_data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Converting other data types to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[2.2338e-314,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [2.8510e-315,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, 1.6955e-308]], dtype=torch.float64)\n",
      "tensor([0.7554, 0.2827, 0.3302])\n",
      "torch.Size([3])\n",
      "torch.Size([10, 2])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Or it is possible to \"convert\" and reuse other tensors as well\n",
    "from_data4 = from_data3.new_empty(10, 2)\n",
    "print(from_data4)\n",
    "from_data5 = torch.randn_like(from_data1, dtype=torch.float)\n",
    "print(from_data5)\n",
    "\n",
    "# To obtain tensor size:\n",
    "print(from_data5.size())\n",
    "print(from_data4.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Operations on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[ 0.2404,  1.1186,  0.6777],\n",
      "        [ 0.7435,  0.8598,  0.7837],\n",
      "        [-0.7004, -0.8703, -0.1228],\n",
      "        [-0.1182,  1.5795, -0.8086],\n",
      "        [ 1.0237,  0.9654, -0.0428]])\n",
      "tensor([[ 0.2404,  1.1186,  0.6777],\n",
      "        [ 0.7435,  0.8598,  0.7837],\n",
      "        [-0.7004, -0.8703, -0.1228],\n",
      "        [-0.1182,  1.5795, -0.8086],\n",
      "        [ 1.0237,  0.9654, -0.0428]])\n",
      "tensor([[ 0.2404,  1.1186,  0.6777],\n",
      "        [ 0.7435,  0.8598,  0.7837],\n",
      "        [-0.7004, -0.8703, -0.1228],\n",
      "        [-0.1182,  1.5795, -0.8086],\n",
      "        [ 1.0237,  0.9654, -0.0428]])\n",
      "tensor([0.6105, 0.6493, 0.2916, 0.6908, 0.8376])\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "\n",
      "tensor([[[-2.0984, -0.1755],\n",
      "         [-0.0574, -0.8822]],\n",
      "\n",
      "        [[-2.0499,  0.1235],\n",
      "         [ 0.4347,  0.2399]],\n",
      "\n",
      "        [[-1.0024,  0.6114],\n",
      "         [ 0.1473,  1.0681]],\n",
      "\n",
      "        [[-1.2728,  0.1387],\n",
      "         [-0.6172, -1.1033]]]) torch.Size([4, 2, 2])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "random2 = torch.randn_like(random1)\n",
    "print(random1 + random2)  # Sum of tensors\n",
    "print(torch.add(random1, random2))  # Another way, explicit method call\n",
    "risultato_somma = torch.empty_like(random1)  # Another way, involving pre-initializing the result storage tensor\n",
    "torch.add(random1, random2, out=risultato_somma)\n",
    "print(risultato_somma)\n",
    "random3 = torch.randn_like(random1)\n",
    "random3.add_(random2)  # In place addition, will add random2 to random3, and reassign the result\n",
    "\n",
    "# Tensors support all the NumPy-like indexing facilities:\n",
    "print(random1[:, 1])\n",
    "\n",
    "# Also to reshape, it's possible to use the torch.view() methods:\n",
    "x1 = torch.randn(4, 4)  # 4 by 4 random tensor, size == 16\n",
    "y1 = x1.view(16)  # now, the same elements are arranged as a 16 (by 1) tensor\n",
    "z1 = x1.view(-1, 8)  # ask to put 8 elements on the second dimension and to infer how many it needs to put in the first (-1)\n",
    "z2 = x1.view(-1, 2, 2)  # now let's ask to do a 3-D tensor with 2 elements on the second dimension and 2 elements on the third dimension, let's allow torch to infer how many elementds it should put on the remaining (1st) dimension\n",
    "print(x1.size(), y1.size(), z1.size())\n",
    "print()\n",
    "print(z2, z2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The command ```torch.view()``` can be used to resize/reshape tensors (by selecting the desired elements) by asking it to \n",
    "rearrange the elements so that they fit in the requested size/dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([0.2163])\n",
      "0.21630989015102386\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# For a singleton tensor, we can get the value as a normal number with:\n",
    "singleton1 = torch.randn(1)\n",
    "print(singleton1)\n",
    "print(singleton1.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can use the ```torch.item()``` method to extract the actual element from the tensor, as seen above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Numpy integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "a1 = torch.ones(10)\n",
    "print(a1)\n",
    "a1_numpy = a1.numpy()  # To convert to a NumPy array\n",
    "print(a1_numpy)\n",
    "\n",
    "# Let's see what happens with:\n",
    "a1.add_(1)\n",
    "print(a1)\n",
    "print(a1_numpy)  # it carries the change from the tensor to the NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any operator which mutates directly the original variable (like in the example above) is post-fixed with a \"_\" symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# And the contrary is doable, too\n",
    "numpy_a1 = np.ones(10)\n",
    "from_numpy_a1 = torch.from_numpy(numpy_a1)\n",
    "np.add(numpy_a1, 1, out=numpy_a1)\n",
    "print(numpy_a1)\n",
    "print(from_numpy_a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## CUDA tensors\n",
    "To take advantage of a GPU with CUDA support, we should \"address\" the tensors to the correct device, like shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "CUDA not available on this machine/setup\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x1, device=device)  # directly create a tensor on GPU\n",
    "    x1 = x1.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x1 + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n",
    "else:\n",
    "    print(\"CUDA not available on this machine/setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd: automatic differentiation\n",
    "By setting a tensor's attribute ```.required_grad``` as ```True```, the operations done on the tensor will be tracked \n",
    "automatically. To halt the tracking, we can call the ```.detach()``` method and future operations on the tensor will not\n",
    "be tracked. To temporarily perform untracked operations on a tensor that is being tracked, we can wrap the computations\n",
    "within a ```with torch.no_grad():``` block.\n",
    "Every tensor has a a reference to a function that has created the tensor, ```.grad_fn``` (except for user-made tensors, \n",
    "whose ```grad_fn``` is ```None```.\n",
    "Let's try this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x11b54bfd0>\n",
      "None\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True) tensor(27., grad_fn=<MeanBackward0>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "# Let's perform an operation on this tensor.\n",
    "y = x + 2\n",
    "print(y)\n",
    "# Given that the tensor y was created through an operation, it has a grad_fn attached.\n",
    "print(y.grad_fn)\n",
    "print(x.grad_fn)  # But a user-made tensor, on the other hand, has None as it's grad_fn\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(x, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}