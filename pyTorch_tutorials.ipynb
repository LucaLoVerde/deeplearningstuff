{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# pyTorch tutorials\n",
    "Taken from the official website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Essentials\n",
    "### Creating empty tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[1.1210e-44, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([[0.1449, 0.1475, 0.0082],\n",
      "        [0.0981, 0.2574, 0.1044],\n",
      "        [0.0845, 0.1505, 0.6474],\n",
      "        [0.3983, 0.2397, 0.1269],\n",
      "        [0.6975, 0.1572, 0.7713]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "vuoto1 = torch.empty(5, 3)  # creates a 5-by-3 empty tensor\n",
    "print(vuoto1)\n",
    "\n",
    "random1 = torch.rand(5, 3)  # creates a 5-by-3 random tensor\n",
    "print(random1)\n",
    "\n",
    "zeros1 = torch.zeros(10, 2)  # creates a 10-by-2 zeroed tensor\n",
    "print(zeros1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Constructing a tensor from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([10.0000, 20.3000,  2.0000])\n",
      "tensor([10, 20,  2])\n",
      "tensor([10.0000, 20.3000,  2.0000], dtype=torch.float64)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# To construct a tensor from data, we can do:\n",
    "from_data1 = torch.tensor([10, 20.3, 2])\n",
    "print(from_data1)\n",
    "\n",
    "# We can specify the type of data we want\n",
    "from_data2 = torch.tensor([10, 20.3, 2], dtype=torch.long)\n",
    "print(from_data2)\n",
    "\n",
    "from_data3 = torch.tensor([10, 20.3, 2], dtype=torch.double)\n",
    "print(from_data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Converting other data types to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[ 5.7020e-66,  4.7642e-38],\n",
      "        [ 1.5192e-51, 3.4656e+179],\n",
      "        [5.0116e+217, 5.4942e-143],\n",
      "        [9.8006e+252, 1.0486e-142],\n",
      "        [2.1403e+161, 8.0083e+165],\n",
      "        [3.9706e+246,  1.1632e-28],\n",
      "        [6.4885e+169, 4.3966e+175],\n",
      "        [ 3.5440e-61, 6.0320e+174],\n",
      "        [3.9845e+252,  3.3103e-33],\n",
      "        [ 2.9999e-66,  4.0610e-86]], dtype=torch.float64)\n",
      "tensor([-0.5843,  0.9068,  1.8927])\n",
      "torch.Size([3])\n",
      "torch.Size([10, 2])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Or it is possible to \"convert\" and reuse other tensors as well\n",
    "from_data4 = from_data3.new_empty(10, 2)\n",
    "print(from_data4)\n",
    "from_data5 = torch.randn_like(from_data1, dtype=torch.float)\n",
    "print(from_data5)\n",
    "\n",
    "# To obtain tensor size:\n",
    "print(from_data5.size())\n",
    "print(from_data4.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Operations on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[ 1.4182, -1.1041,  0.5735],\n",
      "        [-2.5707,  0.6771,  1.3981],\n",
      "        [ 1.3407, -0.5256,  0.3019],\n",
      "        [ 0.0432, -0.5630, -0.1236],\n",
      "        [ 1.7823,  2.8351,  1.3126]])\n",
      "tensor([[ 1.4182, -1.1041,  0.5735],\n",
      "        [-2.5707,  0.6771,  1.3981],\n",
      "        [ 1.3407, -0.5256,  0.3019],\n",
      "        [ 0.0432, -0.5630, -0.1236],\n",
      "        [ 1.7823,  2.8351,  1.3126]])\n",
      "tensor([[ 1.4182, -1.1041,  0.5735],\n",
      "        [-2.5707,  0.6771,  1.3981],\n",
      "        [ 1.3407, -0.5256,  0.3019],\n",
      "        [ 0.0432, -0.5630, -0.1236],\n",
      "        [ 1.7823,  2.8351,  1.3126]])\n",
      "tensor([0.1475, 0.2574, 0.1505, 0.2397, 0.1572])\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "\n",
      "tensor([[[-0.2837,  2.2750],\n",
      "         [ 1.0101,  0.9639]],\n",
      "\n",
      "        [[-0.4132, -0.0180],\n",
      "         [-0.2878,  0.3946]],\n",
      "\n",
      "        [[ 0.9308, -0.6259],\n",
      "         [-1.1363, -1.8214]],\n",
      "\n",
      "        [[ 1.3800,  0.7590],\n",
      "         [-0.8801,  1.3607]]]) torch.Size([4, 2, 2])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "random2 = torch.randn_like(random1)\n",
    "print(random1 + random2)  # Sum of tensors\n",
    "print(torch.add(random1, random2))  # Another way, explicit method call\n",
    "risultato_somma = torch.empty_like(random1)  # Another way, involving pre-initializing the result storage tensor\n",
    "torch.add(random1, random2, out=risultato_somma)\n",
    "print(risultato_somma)\n",
    "random3 = torch.randn_like(random1)\n",
    "random3.add_(random2)  # In place addition, will add random2 to random3, and reassign the result\n",
    "\n",
    "# Tensors support all the NumPy-like indexing facilities:\n",
    "print(random1[:, 1])\n",
    "\n",
    "# Also to reshape, it's possible to use the torch.view() methods:\n",
    "x1 = torch.randn(4, 4)  # 4 by 4 random tensor, size == 16\n",
    "y1 = x1.view(16)  # now, the same elements are arranged as a 16 (by 1) tensor\n",
    "z1 = x1.view(-1, 8)  # ask to put 8 elements on the second dimension and to infer how many it needs to put in the first (-1)\n",
    "z2 = x1.view(-1, 2, 2)  # now let's ask to do a 3-D tensor with 2 elements on the second dimension and 2 elements on the third dimension, let's allow torch to infer how many elementds it should put on the remaining (1st) dimension\n",
    "print(x1.size(), y1.size(), z1.size())\n",
    "print()\n",
    "print(z2, z2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The command ```torch.view()``` can be used to resize/reshape tensors (by selecting the desired elements) by asking it to \n",
    "rearrange the elements so that they fit in the requested size/dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([-0.3983])\n",
      "-0.39826226234436035\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# For a singleton tensor, we can get the value as a normal number with:\n",
    "singleton1 = torch.randn(1)\n",
    "print(singleton1)\n",
    "print(singleton1.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can use the ```torch.item()``` method to extract the actual element from the tensor, as seen above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Numpy integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "a1 = torch.ones(10)\n",
    "print(a1)\n",
    "a1_numpy = a1.numpy()  # To convert to a NumPy array\n",
    "print(a1_numpy)\n",
    "\n",
    "# Let's see what happens with:\n",
    "a1.add_(1)\n",
    "print(a1)\n",
    "print(a1_numpy)  # it carries the change from the tensor to the NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any operator which mutates directly the original variable (like in the example above) is post-fixed with a \"_\" symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# And the contrary is doable, too\n",
    "numpy_a1 = np.ones(10)\n",
    "from_numpy_a1 = torch.from_numpy(numpy_a1)\n",
    "np.add(numpy_a1, 1, out=numpy_a1)\n",
    "print(numpy_a1)\n",
    "print(from_numpy_a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## CUDA tensors\n",
    "To take advantage of a GPU with CUDA support, we should \"address\" the tensors to the correct device, like shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "CUDA not available on this machine/setup\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x1, device=device)  # directly create a tensor on GPU\n",
    "    x1 = x1.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x1 + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n",
    "else:\n",
    "    print(\"CUDA not available on this machine/setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd: automatic differentiation\n",
    "By setting a tensor's attribute ```.required_grad``` as ```True```, the operations done on the tensor will be tracked \n",
    "automatically. To halt the tracking, we can call the ```.detach()``` method and future operations on the tensor will not\n",
    "be tracked. To temporarily perform untracked operations on a tensor that is being tracked, we can wrap the computations\n",
    "within a ```with torch.no_grad():``` block.\n",
    "Every tensor has a a reference to a function that has created the tensor, ```.grad_fn``` (except for user-made tensors, \n",
    "whose ```grad_fn``` is ```None```.\n",
    "All of this has to do with the fact that we are trying to find the optimal weights for several layers of neurons. In order\n",
    "to efficiently do this, **the cost function needs to be properly back-propagated from the output layer all the way to the\n",
    "input**. Automatic differentiation is an efficient algorithm to perform this task, and keeping track of every operation\n",
    "performed on our tensors is essential for it to work properly.\n",
    "Let's try this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x11f970c50>\n",
      "None\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True) tensor(27., grad_fn=<MeanBackward0>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "# Let's perform an operation on this tensor.\n",
    "y = x + 2\n",
    "print(y)\n",
    "# Given that the tensor y was created through an operation, it has a grad_fn attached.\n",
    "print(y.grad_fn)\n",
    "print(x.grad_fn)  # But a user-made tensor, on the other hand, has None as it's grad_fn\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(x, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Networks\n",
    "The ```nn``` module depends on ```autograd``` to define models and differentiate them. This module's purpose is to contain\n",
    "layers and a method ```forward(input)``` that returns the ```output```.\n",
    "Let's now define an example neural network (```convnet``` I think, used to classify handwritten digits?)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # This network takes 1 input image channel, has 6 output channels and a 3x3 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        # Don't have clues about this. Maybe it's just me?\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window, they say\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square we can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This defines the architecture of the net. We have to define the ```forward``` function, while the ```backward``` function will be \n",
    "automatically defined by ```autograd```.\n",
    "We can then obtain the list of learnable parameters using the following syntax:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's try a random 32x32 input. This net expects an input size of 32x32."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[ 0.0819,  0.0214, -0.0185, -0.0544,  0.0939,  0.1009,  0.0674,  0.0460,\n",
      "         -0.0195,  0.0195]], grad_fn=<AddmmBackward>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "my_input = torch.randn(1, 1, 32, 32)\n",
    "out = net(my_input)\n",
    "print(out)\n",
    "\n",
    "net.zero_grad()  # Let's zero the gradient buffers\n",
    "out.backward(torch.randn(1, 10))  # and reset the backprops randomly"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recap\n",
    "* ```torch.Tensor``` is a multi-dimensional array supporting ```autograd``` operations like ```backwards()```; it also \n",
    "**holds the gradient** with regard to the tensor itself.\n",
    "* ```(torch.)nn.Module``` contains the neural network module, convenient way of encapsulating the parameters with various\n",
    "helpers.\n",
    "* ```(torch.)nn.Parameter``` is a kind of tensor automatically registered as a parameter when assigned as an attribute\n",
    "to a module.\n",
    "* ```autograd.Function``` implements ```forward``` and ```backward``` definitions of an autograd operation. Every tensor\n",
    "operation creates at least a single function node that connects to functions that created a tensor and encodes its history.\n",
    "operation creates at least a single function node that connects to functions that created a tensor and encodes its history.\n",
    "\n",
    "# Loss Function\n",
    "A loss function takes a (output, target) pair of inputs and computes a value that estimates how far away the output is\n",
    "from the target. The package ```nn``` contains several different loss functions: a simple loss is ```nn.MSELoss``` which\n",
    "computes the mean-squared error between the input and the target.\n",
    "Example:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor(0.6112, grad_fn=<MseLossBackward>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "output = net(my_input)\n",
    "target = torch.randn(10)  # dummy target\n",
    "target = target.view(1, -1)  # make it the same shape as the output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we followed loss in the ```backward``` direction using its ```.grad_fn``` attribute, we will walk through a graph of \n",
    "all the computations from ```input``` to ```loss``` (the last being performed). Something similar to:\n",
    "\n",
    "```input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> view -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When calling ```loss.backward()```, the whole graph is differentiated with regard to the ```loss``` and all the tensors \n",
    "in the graph that have ```requires_grad=True``` will have their ```.grad``` tensor accumulated with the gradient. Let's\n",
    "try this:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<MseLossBackward object at 0x11f970ad0>\n",
      "<AddmmBackward object at 0x11f95f250>\n",
      "<AccumulateGrad object at 0x11f95f450>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(loss.grad_fn)  # this would be MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # this would be Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # and this would be reLU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backprop\n",
    "In order to backpropagate the error, we just have to call ```loss.backwards()```."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0026, -0.0004,  0.0101, -0.0041,  0.0033,  0.0069])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "net.zero_grad()  # Let's zero all the gradients again\n",
    "\n",
    "print(\"conv1.bias.grad before backward\")\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(\"conv1.bias.grad after backward\")\n",
    "print(net.conv1.bias.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Updating the weights\n",
    "Now that we have computed the loss function, we can deal with how to update the weights. The simplest update rule\n",
    "in practice is the **Stochastic Gradient Descent (SGD)**:\n",
    "```weight = weight - learning_rate * gradient```. Let's try this."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This works, but several other update rules (such as SGD, Nesterov-SGD, Adam, RMSProp) are included in the ```torch.optim```\n",
    "package. Let's try."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Let's create an optimizer!\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# And then we would put the following in our training loop:\n",
    "optimizer.zero_grad()\n",
    "output = net(my_input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()  # Actual update"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training a classifier\n",
    "While data is data, and as such it can be manipulated with any suitable tool (i.e. Pillow, OpenCV for images, scipy and \n",
    "librosa for audio, raw Python, NLTK or SpaCy for text), a few helper packages are offered within torch, such as the\n",
    "**torchvision** package.\n",
    "\n",
    "In this tutorial we will use the ```CIFAR10``` dataset, containing 32x32 images in the following classes: airplane,\n",
    "automobile, bird, cat, deer, dog, frog, horse, ship, truck.\n",
    "The step of what is needed to do are:\n",
    "1. Load and normalize the CIFAR1- training and test datasets using ```torchvision```\n",
    "2. Define a **Convolutional Neural Network**\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "## 1. Loading and normalizing CIFAR10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      " grog   cat horse  grog\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO29abBd13Ue+O177jy9eQbwHiYC4ASS4ijZ1mDZomjHVNp2IsWxmIoSprrdHac7VW25/SNWV6crqTiOu6vTSqlit9VplWRZcixF5YmmJIvUwEkUBwAEiPE94M3jnefdP9baZy28ARNpADfeXxUK9+1z7j5777PPud+ajbUWHh4eHh7dh8itHoCHh4eHx43Bv8A9PDw8uhT+Be7h4eHRpfAvcA8PD48uhX+Be3h4eHQp/Avcw8PDo0vxjl7gxpjHjTEnjTGnjTGffrcG5eHh4eFxdZgb9QM3xgQATgH4KQAXAbwE4BPW2uPv3vA8PDw8PHZC9B1892EAp621ZwHAGPMlAE8C2PEFnk6nbW9v7zu4pIeHh8ffPMzNzS1ba4c2t7+TF/gEgBn190UAj1zpC729vXj66affwSU9PDw8/ubhM5/5zIXt2t+JDtxs07ZFH2OMedoY87Ix5uVKpfIOLufh4eHhofFOXuAXAexWf+8CMLv5JGvt56y1D1prH0yn0+/gch4eHh4eGu/kBf4SgIPGmL3GmDiAjwP4+rszLA8PDw+Pq+GGdeDW2pYx5r8H8OcAAgC/Z609dr39/OZv/iYAoNPphG3GbKeduZYxqT+M+6Olz+D/4vovvuamcwCgQ416NHbL0HT/nc0Hw96qlWLY9uZbLwIAzlw6AQAYG5kMj917x2MAgP6eYRlbxHBfMrb/9TP/8rLrJO5/Jfxc77QBAM98/c2wrVGgPuIxmUBPvg4AKBerAIBsIhceazcTAID52WbYtnuSju890he29fVkAQDn3j4PACiuCSdYWa4BAHL5IGw7/VYJADCxa1fYNjGepw8F+i+XGAmPpdI9AID9B/aHbYcOHwEABAmR6OKJBM8vhs2IcVskImOLRGlMf/gHX95y/urySQDA4mo5bKtUaGunekUNeN/RjwIARvoPAwBefOFr4bH14iUAQLlUC9sCQ9c3ap9ks/QIGkNtrY6MMRHv4bllpN/COs9F9l0szt+J0H1PxxLSB38uVxthW7VW5U8yjlaTxhFE23xE1rHRMHxN2X/Oey0XkXswdfDnoXEhJXs0HtA+WV8vhW3DgzS24Yy8hrJ5GueZ89T/0kw9PJZJ05g6bdnDyQztz5QsEVr8MLeYn0YCGXe8TdfKxuQLa+v0bHaa0m+0SN+N1um8WlHOj7RSdO2krPPc8goAoIkNGVuKrluoUl8DU3L+9IU1OrYi1xzenQQAvOfu/wnXindixIS19k8A/Mk76cPDw8PD48bwjl7g7yZulHUDCGmuUfQ4/KT6DX+Ht2HW29hf0WGW0VbU3jLjbltiCm1FwK3rV3XsvvrW22+EbX/8zGcBABtNMixPTtwdHstmiY1mc+IxFIsEPN72ljE6lOrCDHtH6Bf/fT8pJornv0bmicqqMOoBZn97d40BAKIxYX+XZogplTaEAa2uEAMPLgrL6B2hCY7vo2PnjstaZfLEYA/cqbZZi1jGubdWwqYsiJ2N5QcBAKlYMjwWsPQxNzcXto2NTwAABkeVxNCitbHRrVu63aZjkUDmpyW+zUj1EdNLp8TltTJDDKwnJyyqr5fGnctRvyNj0kfH0DpHjGK5DWLjirhheIj+cFJWsynSSjxOkmKrrfcfs3il/Gx36N7H4nTNXErYdipK343HZByZDK1HNCZrtb5GLLRYoO+msorFJ+g8LcF0QCy+XtIS6OXIJGQuBtRvVD11jRaNbXFF9nW9ReNMxOl/05JrLrLPW1YEQGRy1F8yLhKDDei7qTQ9S2trsl8DfpYiETnfdHiudblWlCVQlEjCMFVZj1ad3wGtfNh276H7AQALZZF629FlGiO/l0xanr09U7THV1IioeV6rv8d6EPpPTw8PLoU/gXu4eHh0aXoOhXKdqH/JjRYipjYYbGloQwTzVaL/18EALRaoh5otUjEaymdSLNDIk+jLWJOtUbiWKFA4lG1KqqLSEDiWVSJ8Z02jem1ky+FbfOtswCA3DBdv5laCI+dnqXzhofEaDfUR7J5MhDVwmbMXyyEn/vHSfS+/xER8ZrrNM5Tr62GbY0GicFlFhMTKRFl2zz3plqjWpVVAEkxXPXmSY1wfo7W5Y0fXgqPPfAoqTgee+9BGWhpHgDQkmGgP0WqkwwblpKxeHisE9D9SySUSJ+kddB7JojGLmvTKpJmk+aid04QDbAT5s+TuquTlftoLPVxfnotbLOJ5wEA2TTJ9I3KenhscYVUEhtrSmXVT+sRSwlvavEUEvEEj1VGWSrSPTURGUc0Qd+1Vo2/wwbINHVWbMieLFWb3Ed/2NbXfwgAsFYQr9+KJZXZsZO0/4fFjoxolNayWJS5TO6j9W41d1ahZJNyH909aNVkj7VaNO61ZWVgrdDxnl5ah2REGf7m+UNExnHgEK1pLitr2mR1mqnR9SPKALlepDVaKsv59TKr4mqy9qkKHc9Haa9tLIvxtdOgOY8ekUXKxFjVYmXONVaZxXK8VspAPTxMz00qoVW8XoXi4eHh8TcGtw0Dvxoc83b/a/blSLlm1GvlJQDApeXpsG2lSIawSoN+ymt1cRNr8K9luy2/7o12lc8TRlOr0S9xoUiMs22F+SZTxIpsp63Op35r0i2SOWZMoPFmo3KwskZGkO/96Ith28HJBwEA+8fvx06oF6vh56BFxrfCkozbsb5oRhl72O2swFKELQhrTSbIVWp8V0rO53VevCDrdqGXPjeK1G+jLNLKmVP0hROviQtlZY36G+oRA2Q+QawlyZJLRDGRSEBtk5PiapnL5Xg8Mt4I74e2Y95KUnPGt05b7os2aG5GsUhzSiuJp1Eldm1b0m+NpbBIkw2AazLPZMBujb2yfp0Gfbe0IoyzJ0Nz6cmRFKJd2Zos8YwpOpxK0VpVK9LHRpENwm3ak6UNGUeEH/FcVubSafB3O7J3ezPU73gvSW2P3POe8NilObIezjVPy/zizPY3dmaNzqgPAPE4PRs9eWGobUv3o63uS7VC5w0wAx8fyYbHAtAcqmZRxt1H/TWVm25xieZcXSKmXFuXe7DMBtPFWWHUyYD66MvLeeN5ui8DWWqrV2WMY5Pk4juxSyTRYyfI9bRg5b60+H3QClj6UHw5FaNnXzsmDA7wM7GzULMFnoF7eHh4dCn8C9zDw8OjS3EbqVAui4u8wnksKiuxq1IlkffS4pmw7cT55wAA55ZeCNvqETZeBiy+qMt02GjXUiqUGIv07YbINC02Srbi7Fus/ElXK/UtM4mxsazTkotVV2i8dx7aBwB4eELUA2WOVDu2/v2wrVi8SONt7uwHPjguoma5TKL0yqyIc/NkN0VFGQ8H+klsXy2TYW5jWUYe9NFvexCVPlYWaB0WVHTc9ClSVeV7SGWQzEgf02+TiP615RNh29QgGWdHe8WwFIuyYY7pRKMtqpG9u2htdu/ZG7aFt94qoytHJjrj5HbGbmdkBsQfeDvUmqSO6o/Jmg6wyscGYlQLDK2Ni7JVAZMolVg9VRF1k23RNWPKgLpRouOJLO2jWr0nPBZPkcqgY+QxrfP2bFsR98usKWuxobVckb0WS7AhrS1qB1uj8TZqomJrsyHvA499EABw35Gj4bHiFKmKvvHNpbBt6SKpI1MJGcdmNBpyD9z+GB4TFUqFVZOJjuyxdb5EKk79ZvvkeTRRmtf5eel34SKtc70gXPTUm3T/gnW6Zt7INVeX6PmKqu2xe5IMvJO7RVV1eGIAADDST+rIwzV5znMZ6jeRkvdCoUjjPb8gKtv1BqndGhW6ZhBX6jc2CG8U5B7kWI0Vv463smfgHh4eHl2K24CBX26cJDCDUEYqx7grVfo1W1iRVORvTRNbPT3/g7Btef08fc8I5UyyV12EXbGMYmSdpmPUyvjF7olW5Z1w7mQupUinJSzQMiOMJYWVJDjarVoWo0nUElW7I03uXJU358Njb18kNpyeECOfyVLb+QsvYycUl+VW2jYx5MVzwl5O/IDY8NKirEcvs+A0G2rKKuqyt4/adu0VFlph5lYpyBplM7yofK/6+sWwk2TmGGkKT0hGqb+oMiIGUWZI7Ao4NiZ5UvYfuIM+KFc6txfiUc2oWWLge9pqtbacr907ryTj9fWzUWtA+nc5YWxE9uT6Bq1ps04MMp1WzLpA1y+XlCGPaV9Wubw16jS25SWSmpIqv8vgILmPXpwR9lwp0bXyOYkSvXCB9k88yW6eyk3RjclCGT05/0ZhUVhleZkZ4cyPAABrC+Laeu8Ryj2zb/xw2Hb6e+6asmc2o6byr0Q4OrJaESO32yuDEzKOjQXaY84foWmU9b9JEkmrKHM/PkP9ZoPBsG3uFLlH9rDr4vC4hG4e3EP7dWpyT9iWYsrbqIsjwKVpmn9xldoKDZlnEKG2oUHpI8fG6OF+CceN8vUbSZJWWkrSiAf0fKUTMr+I2VnC3gmegXt4eHh0KfwL3MPDw6NLcRuoUJy6RPl1d0jUdMZJAFhaJbHo9EUS8U7OiJFvbp3KcDasRMKBDUxOdAOAdtP5CtOxIJDpO3/ZiBLV3TjadRHHIzzOJKtGOlGVBpeNLIFKHGTZ13y8V0TjWoPUCC9+8zUAQH1axNUljk67OytRlJP7WC0QEVULoELlALzyzYvh506EDCOzJ8U3NrB0fZfgBwBWF+m8Zo367x+RYz2DNMbd+5VxlKPoNhbE8JJM0niHBkmsrZVETIwmSORNZMQHOcFGr6iKtozxeYPs73zXPfeGx1wUYqMh/To1iY4FcH7dTnWijdzufB2dqY9vhkti1rzMaExttZqK3m1wv+04X0f4UCZDn4sb4mtteM9klC++YbG5UiZROq2MwNVqi/uXea5yRGAsKmq6fI7uUa3Jkb0NGcfGqjPEi4X17ElSYyxfUH7rnEzLJWB67eTZ8NjyOq390KioiBqcTau4srMKxXRkLm5+NTW2OMcu9AzJXAYH2K+7RecvrMs1081RAMCRcUnS9v1TpFYsW1HNjLNabyJDcz54WJwEmqze3FgRVeJFTgUbUXo1p26LrnAsSFkMuJkUnVgvyxfa/P6IpkSV05OlhHQrHVKhlIoyxhZHGDtVJQDYG0jo5xm4h4eHR5fiqgzcGPN7AH4WwKK19m5u6wfwBwCmAJwH8HestWs79XEluN/oRlMMCMsrxCbPX3wrbHvjbcoRMr1KkYqVqKqnzLkRbF2lk2XDo8poGSbUBxvVyipyrtkkdhaPC1tMp8kwkVDpTRMxGnEqSX00VPRnml0KWw1hbuko9bEnL25wLxwjdvMa5w0ZzYrBcupeYgsPvl/yh7TyJGHUOzvfLpWzHjHQr3rcbC1mkUrqdKWcU8QyaxWSi6VZYo7pnDKy8DXSGZ3snySMSJsY+GBOjDhD/eMAgGxKueP1URTb0KCky61xgYGXfvgqAGB0l6zVyBj1F4spg6XLOaON0Ox62O44Y7RwE1fQYTvXwu3AXl8oxIWxVyq0DpcWZc+0uNBBijdZT6+4GLoCDdGoSBolNmzOQySYnj7uI0N9bGwIM5xlxmYVA49G6RobBTkvz2ltZ0/R2BbnRBJNcaWDtVVpW2fDXEq5YboNZNi9sqWkjzOnzwEA+vokP0/EZvk8ZWTcBKuKQtQ5FFkJUiiyy26zV+7jGEc3Vsp0YmFB9k7S0l4IlEvfaJrml8sKk62wy+4AS37LZXm3vPb62/RBPbe7hmjvxqOqGEmRNoGL8J0cEcPpnnGSFJeXZC/0DxHzTqblvHqaxr48RxGs6ZSMI8kG+JKKqLUJmldsZ8/MLbgWBv77AB7f1PZpAM9aaw8CeJb/9vDw8PC4ibgqA7fWfscYM7Wp+UkAH+DPnwfwbQC/diMDqHEeiQtzUvDg5JnvAAAurZ4K2y6VqPhBPca5N5RLTmWd2gIVLJPJuux08uvuMr71sB6slZVfy0LBufmpTHFMSbW7YYp1tykufhCozPoxzumhz880KSBg8Zi4EbbWiJ3d89ABAMBgnzC3Aw/T+QMTcv4G55SI1FQm+01w2QMBcXVLpoSpVIvMaJTUEURdiS9iW6vzkp0uxeuHtgSWRLh8VjYv+vwYu6dFeIyHpu4Mj42PUOGFnh5Z596+Qb62jG1llfSur79JZcumL4nb3E9/lLjDHXcI+3NMulIRJjs+QWw/ymw7mRSpyenKtc78Stkvq8z+qsrFq8A5P1aXhZkazi4XZbfDwrpIPI54p1IqMyUH8qwovbG7B5nc1lJwjrUuzIstaJTZX++A3AOXZbPDkVDNplrbRfpuRcgf4jz3aFzZEFi8qjt7T1v28MIyCdez88LiA76G7aiON6FtZBwd1oeXCjL3CEsdVZXRMJXgsnAJCq7ZO35feOzMj2gcpbIU93Asu6KCvy4ukkvmBrPcmsovM8useWpCsjP2D9OebCk3wkBX3QCQH5bzYzl6JtZVBtA851Ppycu+q/ewpD9Nc4+0ZIz5QZfFU+xajQLNPfcuM/DtMGKtnQMA/n/4Kud7eHh4eLzL+Gs3YhpjnjbGvGyMeVkzJg8PDw+Pd4YbdSNcMMaMWWvnjDFjABZ3OtFa+zkAnwOA8fHxLVakmWkyKrxy/Nth22qD3OvWmiJeNGP08m+xW15lQ8SdBieB19F9zrZSrojI5hLTp9iFJ1AugxkWxaJR7eLFEXZKFRFjX6MORzvG1DVdbz1JcSWaP0l9NOZEJJ3cS+LYAz9FkW25hPQf7+XCEkodZGr3AAAGkjqd7JvQGBoTkdoZooprIuIFDZpfTeW/iLOhrY/zfERUHphalea3sSjjGBgmg9HAoKqczgbkvjgJYamUjCPCrlgtZTxssSufUbGQpRqrd9jYNDMvuVPml0i9MjQgImyDi28cPXpP2PaJv/cJuqZLHatcBl1tSd12JYNmm13dmg0Z4zqrR2oV3S+t6VqBjI3RjJyfaLNbY13Vs2RDeacufRTWnOsp9R+Jyn41JsXzlX4vnGU1V02Me9EOGx6XaF3qG2q9eQ45ZZAN2LgdVUY7R+WybBTsyYvaq1ah821HFfLI0vUbVtQ7m9FWKgPDF8hmRDWR5Fqb5Yrsu3k2wPaxm+x7DzwcHiukvgUA2FiVfb3Erojn18VFL8VOAc4tcKBf9k40SeqPHplKmE62oSKuE6yKK3EepFpU3DBPz5Ma5vj55bCtbxepQ/ODcq2TJVIL1wKuyVmW/hfXqY+OMs5vlHgdLvcQviJulIF/HcBT/PkpAF+7wX48PDw8PG4Q1+JG+EWQwXLQGHMRwL8A8K8AfNkY8ykA0wB+8UYH8KNXXgcAHJ8+HrYlx8hpfr0mBreqKw3FxstYoAI1OPdDJCIuWyk2QkRU+aV2k75brNIvYiYtv6qu2lFbGUczSXYtjAkDikddgndmMSpfSz5BAQS1BWmb4Wx9+8f2hW0jd1F/Pbu4ZFZNAmgqFc5KVxB3vL6e9wIAxvvuguByBj68S25lIkUso6xcwRbOElNKtsRC0ss0JMA2gSscdLK6KvdgaJSoQUcx9WqN1mFygAys6axQm4Ali2pTWGUP06JITKSOJa4a3uTq6wmV4c4VV1hclECKvj6a38MPCzvLZOi6LlukdiN00G3bHXfotFlyaGw1QDZqwqJcfhFXpECXgltjlhbpCMPq53wZI6NyXrXJ2QgtrUe9LGvV4TJnA2pNy2vEOLMdMZZlOa/GyCFif4M9wlCPnyUpVleDr/Fz4IyePEEAwNF7yIXzfR86Eh76wfdIIn75h7LncmzIPnRYXD43o7gm7NzZ9ZMpGbdLV1MsyV6YnaP7t7BCTHykdi48Fme231E5QxZKtB65Ucmfs4cNjpVZcjXOxGWeY8MkKdYLwp7bbOHV7sLTc7TfKrxG+THJe/LWGcp6WlQ5fuJsqL9UFK3B+RVat0iW1rutnr2lEheQUe8nHcx4rbgWL5RP7HDoJ6/7ah4eHh4e7xp8JKaHh4dHl+KW50K5ME3+3fv3i59vK0OGto6KHotwhF2tyukxlbqkw/Xlkknl1xpln0olPmXZJ7fF6hej1DAZNq602zrvCedCUT7WbUt91Nh3tbyhPGsK5MP91ouS1D0zSGLTxKMiBicG6LtnztJ5ldWB8NhYPwk2k7t/ImwbGpri+SnLyyaoYubIZEhkO3yf9GvrtEbVjZY6j0TGAqtJWhDxfWCIxNBiQfzRl+co+m9sVIy0IwMkWo4N0P3rzUmEZSxNa1pX4Xc/fJXEytNnzodtHfbVd3lo8j2i2rrvXios8Pxzz4dt+/aROmpoSLxXXa4Ul2NFq0ic8VIbMXWV+81ocCRtUfks9/XSerRUNOzQOK1fNkf9blzYCI9V2fe3qSrEDx4gNdPUlKgdVrlm6/oC7fWsUusduIPSDff2iC9+pcTG/KbcF8v5c1zunh/fLfdgzy76/GfPHQvb1rn6esLIphkZor31kZ9+gP7eI8dKZZrn3CVpO3CA7vfklFxrM3qzssYRNpgGymjnfOqX5uT52tjg2px8/uKS1OGcu0AG3Kry67astgxU0QsX6zCQp/WuqYIstRL5kgeq8GSUK8o3ZHtgboXWd2I/pTOOKO1ilnP3fPTv/kzYtucAPWvff+OrYdt8gfzV6+w0UYEqFsO5ckxL1EeRyPWrUDwD9/Dw8OhS3HIGnuPoyFH1a73BmfgyvQfkRHbHMi1yXyosC6ubXaHcIqs1MXTZgA01OsCNWVcGzGTbqoQYu3hpQ1TbZVNTOUUqVWKhzTpnY1sTVvzqyzSOwoIYkQ6/hzKonVw6Gba15ul4AJrLWP+j4bED+z4CABgYFKNM1BUuMDu7vik7YZghcHh4NGyrLtIcps+I8WZ9hdhIjfMx9A4K+0sze04npW0gT2xrjyoBl0sTy7k0TX2dPCFZESstYouXZsWws7xE562vi3H0x378AwCAJ554AoBIQwAwtXcKAPDCD6Q03sEDtC90VfpajYxCac4wGYtpZrPVtTBQ0bKb8dBjnO1OGZUiAbHgakPW7/ARMjS/9gMyls0uyX0vF7niuqpiv7pADH02IZGEDZaM0uzelo7Jegec5bBTU6Xj2I22WhMGPjNN+35tiY4NDwpj7x+nCNVdKvJwYYOjmpWB9eCdJM1M7aN90mqLAfLBo1MAgEmOrAWAMpeMm1+Q+43EIWj0qqhE61xbtZG2TfdoeVGYaXGd+p2YoLWfmRMGvrRC+ymelfm5cnzRurwPipxDZng3zX14QM5Pxl2EsYyjztbUhfkVmZ/bKgGd31AxLAN9tJZ3HRHHhLl1MvDOlaSsY9W9P9idNpLSxV/oAjodTaO58/O9EzwD9/Dw8OhS+Be4h4eHR5filqtQBjNcCGD2Utg2/DCJagVIysxEnsScXJSMBUYlVDowSuefmZX0syvr5D/abooo2GQrhQt8jCuDSsQ4/2EVacfJqdpNifJKGq6+HiFD3osvSeL7498jcXK3SnxzllUKx8/LOHZPkgHo/T9GBstH7v874bHBwSkAQFRL+Ndg2yguiki4wNGh0ydF/CytcGIuleKz1SSxMJvlCMtRSWvb5OjWwbwYCod6SCRdXBTj8quXSGRcXiLxs1wRQ54rMNBSaoQeNixlVaTf8jL194+f/kcAgMkpUf3Mz5G64WMf+1jYNj5Ox3VRBhdZ6dQkOtLySuqS7TB5gH10VVX1OhdySPfKOp9+iyLtvvttUhGtLMl46uxXbVSNVbDP8uppUTv0pul+3HWQ10Op69Y3SDXSaEnUZYuNorq2ZIUN6RtrpFZZXhH1ijlLfWT7ZE/m0qTaqKv57b+L732CDIVJVZTERSxne1QdUzY8p0+IumtWNJjUv1IJVFnFsboq82tU2fjaUEnX1kmdshyhdc53ZPM7A2g2oxwY2Jkgqx6YCKcvTuVIFdszIEb3NU7MVVDFFZrspNBQ1xoaJXXhrt2kJksof+0GJ/CqGnkOFtYo8d56VVSDZY4d6MnSOkSjaj9VuN6uergbO+cF2xGegXt4eHh0KW45Ax8bpV+4b/75N8O29+4n17H0kPw6rTWJ6VVBv5wRlZchZYhRTPWJkSXHP2ctxWjYewqlJv1y6oiugBm4i9YEgAT/MueiksbVFompnP0h/dKuHRej1hAnYBlsCnvJcl6UWZWWdWLgQwCA99z9C/S9gSkZR9SN9/puTQTCQEprju0oltHgSFZduo5T4fYOElMZG5N5Fpc5B0RB1uiHZ4lxrqoyYW02RFmO5mwZmXtoA1YpdyPMhmMxmd/GBrGi559/DgAwMPjR8NjAIElcDz70nrBtfZ3O15XnHeF2zFuz8+3Kp10pF4p1PmNWpRGOcgRwXIxZx46RtLFYoGMVFdlot0lhu1ilfm1Z2Nw+Nu5dYENkXDG90Qk6v1QUqaZRp3tar8jcC1woYo5dRBvqHrfbNN6Ych91xyOKEbYNSYhzK8TAVXqeMBdQJi1GyQgXluhcwfWtJIIACrxlFhfk+TLs+qc8dwF2Doi1qP+oSgcdTdFnnYq4vEEXyfZKlOPwELFnl2K4pZ6l6VnKszNzScSFyT1TAIAHHpDUtYvrlN5pcjdLgx2RoNdqJHWfuCCurdleGrdtiERSZmlicIBdlDuyd9yskqqATLG+c16ZneAZuIeHh0eXwr/APTw8PLoUt1yFMnWIfEfX/0DkqL/8T98DADz5jyXSqZkhtcdam4ydiYwyqMQ5nawRK4DLmbOxIP32DZD/cpwNoUEg4qor4JJKqVSpUTKGtNck2dTiORJzeptcjT0uols5IDnx7oNiNDnyOIllK3Ex2t1x6OcAAHtG7+JxyG0wHCFmoUX8q1sxh/aL6Nabp3Fn50VcTTq7j/KFPnWCRLpergreqcr5c+dJNF1Qlqkmq5e0j3WH1UytlvtfV35nw7BSoViuv1mri3xdZ9HxR69RhfGP/e2fDY8tL5Eh++RJSXY2zAmJdLSlU9Nsp0Jxhk1XaXzz581YYP/4kSEx6g5mSL20qlQXq+uIVeIAACAASURBVKvUb5ENUkalFg7AaXO1yooFZ52zaIX9ouucUCkXlYNlTpgWT8p6lzg9ckGpYYo8plVOYdtWapsY92cbKpqYeVtCGf5WC7QXzpznZ6gj6+eq3idi8nxZvrcLszK2zKZKMqsr0sc6+yNUy3K+qzwPFd16aB9F9t45TOqP5RmJIXA7Zn5eyu/WqjTu0ZHxsC2bo/tW44pGy0UxLM4t0kCicfW89JPKZfdu8euOcSxFrULPdCyufPxblAL7kqqmMw66fj4tqt1FvlarxM+yUjdxJl0E6nnMJK+fT3sG7uHh4dGluOUMfHAXRRweeUCiEb/x+d8HAIwP/Chse/jjVKW9zYnpCzUx7IDbgryqEM9sJxYXF6zZ82SYKK4SM8jkxbCYHadf4YRyT1zgyLaVGWEv0RJR9YGMG7/ktchnyVVraLdcc/JO+jzet1vmnCYGGXU1A7Xxi1mUDTTr5twt2Blj+8W1KmCWe+G8sNxOPc5jFFbZaZFUU2X3tvNnxS1q9gLXujS6UAQxCRf1CEitQ8dyNfONBlu3l8tZoo17zhh5z71UoGF0VNwIL16kKMd6Xa6ZYPfOVEooX4wZtWPgun/Xpg2XOipzM1ZWuJZiWxjWuQqxqWp1q2scOi6Xi+o/vKW6Diezd0XBi5x3pc7LVlXnr5dLfLrsjzq7utXUXBpuruzuF1ERqhGONg6UMdAZ8zUjXFmtXHYtLf+1WySFtVSykIjLX9OSZ+jOw7gcVvZOoUAsuN2RfVpiqSOflvs4yrUiM5zXaPiwRHe+eIpcg2t1YcO7d5FU3T8g7q4BpyN+4wRFP1dV2tdcH0lSQVTmsmvP1mIknTZdf3w3SdOVtkRptpv07okpV8v5AuW0ScrjhYlxuh9NdkE1MRlHhl8RMWX0T4ztnJ9nJ3gG7uHh4dGluOUMPJ6kn6KHPviBsO25Z/8SAPDSX30vbMsNElvd+0HKg9GIvB0eq9U5R0JEMqMVAvpl6xmTX7gxdqlqct6OY28Iw3qFajQjkRQ20I7QNdMpca87uI+uP3aImPfe9308PFZZJRes8vR/CdsC1tPW2rosG9H3jsttEgi7tC06v17RLJcTzl8hG2G/yljX5NwZjaroClfnqL+XZyQPBziz4vosSRjrCyqhChcMsMrVstOi421VAdwRQRcso3XLrpRZtarK37GrZVu5AI6MUKGID32Q3Cu1e+CZ0+Q+mssJtclkMluu5dwTo+yeqBm4kwqutSp9mHJGZb1rNYhBFjZk7g1XAIOZ92U9OpatGl23l3kw8ucms+GC0ZyKg5I6SkJznEsHCG2aiv6zE15VWjvM0JNK55plF70st9UV226yrSiSUFINM/tIZ2d3zIV5fd+5OEpcngPL9pOmCmBxuWFqEWLZgyNSXyyTpj3QNyU2qWEuYRbq0wEcO0XvhsUVkqDbKufL5CRJ/KWyPPvrawsAgFbrYNiWSNNcYzkaz9lTUsxikd06I8peFmE3005S9m7PMD1DRS6bp1IvIcZ2u5gq44bmX4MO3Biz2xjzLWPMCWPMMWPMr3J7vzHmGWPM2/x/39X68vDw8PB493Atr/wWgH9urT0C4FEAv2KMuRPApwE8a609COBZ/tvDw8PD4ybhWkqqzQGY489FY8wJABMAngTVygSAzwP4NoBfu9GB7L/jjvDzBx9/HADw5f/wO2HbC8++CAAwcRKH9r5fjILnypSHoBHoyDmq6TezcCpsy3IUZyLNyfaVYazKVdsDI+k89xyiPu6+74Gw7a677wYAjI1RBGk8K0UTCktkyHiz/lrY1na1NusqUnLJRW+SOBlVqpEq19Qrzqm0lOyyuPew1IDcjJe/KaqRcoFl0roYjJwrU2VZRNiAI/GKdWdck2PG5YTp6MhKZ7AUWdCpMVyBBKc2AYC77iI3yePHxQVwfZ0MpboqvftOml2wvvvd74bHzp0jw9Wjj8jcs1wRXV/LGTHBqhFtsDTbtF0J+8ZpDwyNyONR5Yri8ysy7mNv0H20zsFNGQqdHuayIhJJl+pWznPGxQq7B9brSqRm9ZvW9pjQ6KXUWHw/LNfyhMrpYVg1EyiVC9s6cfCgGNtHh+m8TG6rEdPZRJNK/ZHgaMhquR87obAu6rcYF1NptuSZa7HKYG1d5Rlhb9vUIH1YWhVnhQJHAO/fLamWe9gov7i6ELZtOPUjR4umYio6skj7L58RlVySU/iurYvLbCxDz9Dbl8iR4uKa5Dxa4erxqaaoW7M8bqvcQN1dTqRpn1plsDQcca1dcgOl6rlWXJfSxRgzBeB+AC8AGOGXu3vJD+/wnaeNMS8bY16uqJy6Hh4eHh7vDNdsxDTGZAF8FcA/s9YWrmQE0rDWfg7A5wBgfHx8CwVyvSRVQMyHP0KJ/V/+7l+FbZeOU0moY98kdpvtkRwCY3eRA/70imR5a8XoVzhISVDN4gb9+iYH6LsPfvix8Nju3eTGOL5LihUMjhPL7x0Q42jSRfy4gSvWlephNpKR37JKm1jahqpWvThLRs7MKLH3XK8YT6oblKuheloyCfYMvw8AEO3sfLu+96ezcn6ajDx798mve38fDXg5LQyowdkIoxGXq0G72ZFRRpPW0DtN3fpd7Aaa5lJgExMSUPHJT34SAPCd574Ttn3hC18AINn9AGBhntjTv/2t3wIAnD4j0oczjg4Nyn285x5yN9SGza2mOoFzXdSM/UoZCitssJyZE/a3zEJTvaGDhzhYZ5uLujiYkVGR6D7yJJmJxidkrydZopydIcb36ksSdHL+DN2rigqwEuYt44jFOVsgs9y4Ki1YqtD5i6poQi5N333oEQku2zNJ10hlaY1yeRl3s0rjiClens+StHThgqzpitjMAQDRqPQR47KHVpUys+yq19KFDLhUYhu0J8+en5Fx85jSKWHUPXna60Yx2RVOwpIPSMLIp8XAn2PjZAQiHQz1kTRdrMkEih3KbLpSJ+NlIFNBfYnuWbslfbAvRsi2AcBYus9Bgl05Vf6fDieAiaviJbEoS+Iqh8zVcE0M3BgTA728v2Ct/SNuXjDGjPHxMQCL135ZDw8PD493imvxQjEAfhfACWvtb6tDXwfwFH9+CsDX3v3heXh4eHjshGtRobwPwC8DeMMY40Ij/xcA/wrAl40xnwIwDeAX38lAjFJFjHF6x1986h+FbZ/9l/87AGDmHBkaIn8hhsKjloyMew5MhW1nVmiodWU4aEVJxdGzj1QXU0NS+f2ewz8FAMjoenuBMyJpP9zN45b+owmSo4Ks+K422iSWpXpELmo1SCzcYDm7VJBCFINpFofz4us6Pkk+5/GMkuM2IZcQQ2iUU5SuLono3eKP5rL8IQluY0OX1pewIUz7fDv/6P4hUSk98cTfAgA8/PAjAICZSyLynjxFkXA6dezRo/cCAE6/LSqiDU6y/+xfPAMAGFKRmCk2bP7Znz8bth0+cpebQNjWaJCIHmM1iVaRbC72cDXEorT20YT00Wa/5GpN1lTSoHIOErVWo6Mk0j/9P4hK7r4HnaFcHJ+jAY07eITu7UefEKPg7CWXFljUHy2+hlE7saeXVElDvbT/InHp/0evkfrj//pt2WNxjgjcp1Rs+/bRXiizU3Y8kD7SPb08X+UbzumaG02dC3YTVHGUZJL6r1ZlLi5fUVqt82qFBPlTF8p8Hdmvw4PURxCI6iLXQ+uWHZR1OzVDjgs5jvDsz4mxNpelvViviaqqVqHPtaREWy512GiZoHlmI6L2GuyhfafTUYNVjrmEqFAsp7le5f5LRVmrgFVJvVkV3Rq5fiPmtXihPI+do7h/8rqv6OHh4eHxruCWR2I6GJU8H8zYHvox+X0493GqpP3/fZZcC2vHhME16/Qr9r4nfjxs238HGbpeOPX9sK3Iv7rpCfpFXitKyTbL5aE1WzQur8YW3q3HrYpCBPTrG0+JEXN15RUAwO57VbXxPLGyjRKxjE5DfpmjAR1L7T4StqUmyEhrVVa6zYhdFpVI/5dKwhY3uLhDLCZMIhJhRshRqzBbIyzbbWFMcXYV/IWfF2Hr7//S3wcg7n7/5Y9FkzbMrmAjw7Ie+/bw/KLCVN54jQpFrLGROZcX4+TTT/8TAEB/nxgx7z1K97ZclpwYq6tkZXQSho7mdNB5WpxhcztMz5BBOJuTc8b62W1UGdxc5G3cBUeq/DV/62+TlPKI2MkRizh3P5WRr033pdpiCS0uzHDyAK3RaF3uQd1JGkqSikbpuO3QerQV3ZrYm+C5yDVdkYRUTp65ToSjC1219JoyhNZobIHafwEzarNNvhuHdE7W292XclEZD0dpL0ZUNGKTo4dbbJi964EHw2MNNk7Oz18I2/buo/vSNDKOBj+Tuw+Q5JpQErRpUx8pLbGyFFGHrH3bEvNOMovOxYTF216OIFX5VOqG7mOtIvcKbbofpSI5CzSUK3F/uJ1VtC9L5Ds/5Vvhc6F4eHh4dCn8C9zDw8OjS3HbqFC2S/oTS4iv9xP/zc8DABaXyEj2zJe/FB678BaJ7626iLcPfYR8p48eEBn2telvAQAWFsigk+kTY5xtkzojUP6h4lt8BZ937cLKp/Wp1JYrGyQ2NRrK/5qFpESCzksmRL2SaLOPc/89YVssT+Nsm51VOZ2OqjZfI9FuY11UDBGwysLq32z67Ax+Ha1CYYNVsy3+2gNcSX5lVfr9nd8hx6T1VTIAPXiv1BXcP0l+9G1V9NCpAAZz4oOc4vSfx0+QD/zFGTGEOp/wD75fjIHznEh/124xdgasvqixf3m5LPUFXeEHbdjcTsXi0DNI92PPpETZ1lep3uoL3zoWthVW2L+XjXXv+3EZz4d/mgzZVmVqagUuuZJcu1yjtgpbmTsqcVWkVeU2OT/Cm6yj6kLW2TDovtpRQniVE71l0qo2LBegWF6R+x3P0HcCS/ukXpZxXJrjVLpNeTbi7K+9siDP6OCmbEiJpJx/cZpUNMbI+c6fW1csrde5li0ne1KnI29ozxj1LLm99eYpuS8nz5OKJcK5XVOq9meM1RpHD94dtuWitP/yKt5jYYmNrgVO4FaVa1Y6/Dkna9Rwl1BRsMkEzSEeIfVLpaaKN2RcVXq5V4UCqXcGroNWewbu4eHh0aW4bRi4jmZzTFYbhQaHSOv/S7/8KQBAqyIGpr/82lcBANW3JOdGpUTGkAc/KHlMJicoOXw1RqxnoHdMrsm/wpfVu4L7ldRpSMNPOx4bGpZ+L0xTpOKGqoIdMNtpN8iQYgMpCtEzQlnx+4ekjwQb/K6Uy2NjXZieS9Xaacvvc5x9tmxHz8+VIaO/mspNLMM5JkZGZRwTE1Tu6uTJc2Hb26eoDNonP/53AQD3Hr5Tumc3q0CV7nLRkP39wm4HR4i5jo7Ttf7sL58Jj33/e2SE/ukPfyRsm50j4+GZs5Lnpq+P3D+Hh4n56khhx8B1CTb9eTP2TXJV8z3S9qU/J0ng1CmRPlzqCs6yi0N3KFezfppnqSzpI0oVlzNF+m22nOTAxkM1jhQbCGPK4OvscbokmOuuxXlGdI6fKN/vXlVoYJrdEl99VSSduVUu0MDG8JUV6aPAxvCUcpFLRqitpQqpb2bg/f1y0Q1Oqbq2Ivu0sEHX6Cge2WFJsWZpjIsby+Gx0Tjtk1hM+i1zpOn0tORCuXiJJLQ1LqXWq8ovHpggFj99SdyFD46Q22g+Kq67NZZAVlc4InldSWyZDvcrfTgnjL6cSNPJFH1nY4meg1pR9kK1TG16FwYxvpNaJLkKPAP38PDw6FL4F7iHh4dHl+K2UaFsh8u0GRwVOc5+xP/wv/2V8FCLjTx/8tUvh22V0+cBAKV1SdGy/xAlWjr6wP0AgN3jYnRKNBNbL7qt0XBz+ROVnId/D7OZibBt3+6fAQCcuyDqHdugPvI9JLIND0l6TKd+iSWurz5eQxlI4nFSl+zaJeqPNKesnZ8TUbPD4nWOo0/ve8/94bFHHnuMj4n/63PPUYWkixckMddPffjDAIA7DpCvekv5VztVkYnLNrNRWqN0XvpNczWhgWFSk0VU2tJTXF0lTCIGqUr/5puSQndtjYyoLU4wNKSiRbdLJ3ulqExn0K4UZNwzM+SjfuBO8R9e48i6C6dJ3K+qSLt2ndU2Ru5jENDxRltHVrr4AxcVq1LN8l68LO+Wk7JV3csGxxFYbuuo2IQc13id2i/juDhDqotcj9yDtqU5sw0RLZXatHeAohyTKmLSspomaneuElUqiRqmj3U4ybQ8P2m+z/OzolrI9NN9TnLE5PTieTk2Qn00lUFxnBNm7dsrcRPHz9O+iHF1oUAl93JlaMstiYxeZVXL6lmlD2rROFotOqYdKjrs/61sqWGkaVSl7Q1Y31XnGrI6pW+twjVclYE6l722SGENz8A9PDw8uhS3NwNXJp3QpY8Nm0O7hLV+8r/7pwCAeFaMEM/9568AAGqrwtJGLBnOxmJc3XpdovtaHUon27bi3ubcB6+UOdds81dEGe32TJG70tDIgbCtzVaKBDOaeEJFfwbOsLi1IMGVMDgqjHPfXmLDQ8PS5nJo1FW+jqX5pcvO++RTfy88dvToUQDAl774h2HbWU5x298vxpu9+8kAGzDD12k9XbReRLW5IgUxRSsDNtYlOHfFww9L8YapKer/jTdfD9tGR8lQef8DYqB2UZaBY+9q/dr8OaquGTE7c5ckF1xYnlOMnY1UTzwpBuev/iGtR4vzWpQqcn6zGVz2PQCIBMzilKtglAsAOAOkVcy6w/upo4L7GjxPLSjG2LgY4/5NRKSgRI7uweR+Of/FF6jDoWFh4LE0WWLXV+hYXrkdRuP0uVgQA2StSOd3anJvd8l2ozGq1LF1ZrwTe4TJpmJ8z1Q0p6szWW8QG14ty1xmN8g9cDQlkvMEF3cYm5T3wfk5KqwyvUznDw7Le6HCIkapJVGXb0+TlNfbL+uRHKDP0RgbUQPN4mnOScXKs5wyNh6X8UZ5XoODST4WHkKlRGvTVpKgS7mL60iJ4hm4h4eHR5fitmbg2/FO43IeqF+p8T3EOD/xDz4VtkUr5O715p9KwM94H+nyMvEpAEDVijtSsUoMob0hhRGSnF0wmZTznPeZsGK9hMzYA/lVDVLEMrIpPRvnFujY4taZbke6r8TE739I2GiOXQCjivm6H/rJvVNhW7XMSjyeUyolFGF5iWwHz6tiDJcuEbM5dMf7wrY866/brLttqFJfhgtEGM0yHA1Rc3GV011WxJ4eYfiu/2ZTaKgLyGk0pC3KzDusOaFzhTjmrdparZ31jfEYMfwz0+th2769JGEMjci46869jrttNoV9lTlbX0SV2LLWBVPJtRyxi7MtpdmWPiwzuE5HdNpOZWqVPtVa/g6vd6D2U8QQq+sdUMUsOGBrfUl0z4fuY91z3LnO6kAn6m+0X/To8YBLmV1MYSfkBoSh1ng9EJXAsIBLG/aNy8PsahrMzfBz0yvP12r1EgBgpF/07ineKsU1YdRDvVwMYo7mV1Wlz0rsxtg7LArsTkDn9fdNhW2NBM25kKQ9EFe5ZJYL9GxkszK2sUEu8qDuX4MzKXY4GK7ZkPvY5qCotkpcYyPX/zr2DNzDw8OjS+Ff4B4eHh5diqtydkPJC74DIMHnf8Va+y+MMXsBfAlAP4AfAvhlG8py7w4iVhsxXWpXVzVbRA8npY4NSz3G9zz8Hjp/4RU5j13YWnXK0ZGKieFjng101ZIYPSe4CvzkHZLfYyu2qjW0RsSN8/KzLhffL9OMhPlIru+3VReicKGscWVkcUUpRsdElC6w2Blj0S0ayLHnnnseAPDSyy+FbQPsTtbbJyF3rkJ8kt0eO5cZX+l/bZB1aVx1JKRTibgK3dsVY4ilRWwODZbqvHqd06wmt7pfOtWTdh207Z1VKG12jXv/TzwUtl2Y/S6PR9zPjuwnq120Ta6ZubT06dLwOqM0AFh2zQuUa2GDUyFXqzxGKHc1roHaqstjFePasY2mqABcOuV6nN3bGqqQAp+WTYsaoS9N1y/Ny30Z76Pj9RS11VX+mg5oLu2GyvPBrqqmLvuuorzwAEmPCgB5rmGbziv3xzbnelFvoXQvrf1ggwyPzaz0MTtD+/X8skQCv3aGInVnTonqc2yM3GfvMeQ4cHFVoqDbvGUCsVeGle2zOdnX6RwZSg/fRQVIzq++GR5bPUbviHJVCkDU6rQ2DVUns1rmHDX8t8r4jLEhcn8s1USNZV0I+s4B11twLW+JOoAPWWuPArgPwOPGmEcB/GsA/85aexDAGoBPXaEPDw8PD493GddSkcdC6iTH+J8F8CEAzu/s8wB+E8Bn393hKdcdKQO/6YhAu4mNjVMwzdSRo2Fbp0EZ0cppZjQ1ybNQWqFf6U5NaMTo/q0sbRu+vc1I1O9imP1PuQq6AKGQeus+3C/4ZbR8m2tcjmRaKEWEWV9E/eQblyxetaWZlRXXidlsbAi7fPsUSSQuOxwA7GeXQW1kdLlNnNEwuk0OEm18dZ+vlKtEZwqMRrduUcfUNaN25agcY9f9b1dSTTPjzWgyM4xnZO65Xrrm0rwyXI3TOpSLHPijyq29/NKsG1jY1mbRrNmS+12ssIuey5miSgu6/Ci6QoOrN9JqiTEwnXKl2ui8qmLsI6Mc6LJL+n3kMUryMn1aqrDPn6Y+RsZZQlJ72HKF+E5U2mIBt7W1sfNy2LZcs92mPZZKqsIIxt0zOa9Rp7VMZ7hNGf+XVumal+Y3wra5MuWoObssAWoFNhZOcSnCjZLkrzG97L4XEaZcbtK+X1wTRn2gj8r27Rkh/0tVcwWxozSHlfUzYVupQnllOlGVtZD3UTpPz1kyLeuXy7MUtiGG+LbhPfAuM3AYYwKuh7kI4BkAZwCsW2vdtC4CmNjhu08bY142xrxcqVS2O8XDw8PD4wZwTS9wa23bWnsfgF0AHgZwZLvTdvju56y1D1prH0yndw679fDw8PC4PlyX46G1dt0Y820AjwLoNcZEmYXvAjB7xS/fCK4QLbctVLRUvpeiLgd23xu2pcaobWSURKt6XdXi47p4PT0SiTkwTnlXItrKuEWbsY0Pt/68rfZjc6P+O7rDOVdGSlWsd4bEQKsRWGIMVO1AUV2QuKoLS0S5YMDu3WLonZoi429Pj0S2xWOXV/DTqgun6tBtTiWijZhOteFUJ7qAhjNYJlQuFGcI1cZRF43o+ohd5gPPldwjamw6LG4TEgEZsBp1meebb5GIvLgkKrZKk0TpIvujr18QFdSFJVYVKT/wgCM8dR6TZpM/u0INKpeoi1DMpVUaVzZU6tqttSqvW5PWdHFD+rg0R+qG4rqoXPZxoY0gJeqMxUX6zsAw7YGerKxfhBOItFSOlWrdVY2XfjejoSrQu0y0lYK05TjlrolJvy49rYnReZmkzJ3rP6CeUfcuTuqRdI/0cX6G1H8Njua0TbkH1Qqdt7ymVFCGVCex5sWwrb9EBvtalQyig3mJ/rSsJgliKkp0iVSwTeWgYAPany0OpY0pFVSlyrlnVL3TtotN2HlrbsFV35DGmCFjqBSGMSYF4MMATgD4FoBf4NOeAvC17Xvw8PDw8PjrwLUw8DEAnzfGBKAX/pettd8wxhwH8CVjzP8G4FUAv/vXOM5rgo6+qzKjXlUZ0e7fdRAAMHWAypV1lCuZK4IQUYZQE2xlkGGOjesjyNeBG+s4UO5zHeeqp3NMxF3JLPmOKzAwOESSSa5XjJOrBWJuuyalqkGWj1vFZJvMJl1gYExl02vxsZgq/+XYp5N4ACBgVu4YclMZMS1HF8aVG5wjsO2Oyj3iMr4xMw20Rq+z1TUzuEI2wqU5YkWnT0v+lQ02KEbiysUxQeu35zBHi3ZEgklxlGFvr4w7mabvGiNsscL700kyQUwV4WApYSCvigTEnWFY5hfhsGTbISnl1TekavuFS3Qfl1fl/EqNImr3TklRjYERygtUbdI4YjW959v8PTHqNtldrqkIeGRTOfWEmsvoCK3R2ppIKW1eh94h/R2WtNjIqFmuW4a4EYrak+eIzQOyRvk43b8yV7Gv6f3Er7z1DVWmrofm1U4qo26BSrS9zgU8Ukm57y8d/ysaR4/soUSeS8GpCF/r/In5XrXU+6Ze48r2Sjow16txwLV5obwO4P5t2s+C9OEeHh4eHrcAPhLTw8PDo0txWyezulY4afIy0Z7FkVReUsb29pNBouMyYenk+YlN8h+0MkOJ49eQ2vVWIJmThFtxNqq1LksARevRUK6cC5ywaoircV+cuxQeOzdDYvZddx0K2zLs/22iW9UkcVbXRFXdxGqVI+106lNWFejzXNuWlLAQQ2VTRfVFnZokroxTrEJxxsxA+Y87o26nrZIJqc+bUVoh0btcXg3bcmk2YkVVdOEAf2Zff6NVNLz/LnM35wRGVs0l6YycboupWOagRV+uVJXxi+fSVuK4+MrTsYG4FPJITdD+byp1kxPzK4vStsyaxlWnn9omwZpVxRvcfQniqtjmpkcok5aGXk5K1bHStlbiQhhl5c/fpvvHeeTQVmvVN0hqQrWtkU5Rv0nlwNAToz5mVmiMjYSK6OYEZE2jBssFGpASFVEF9GzM8ML058W5wRklayW5WcMcyRrryPNlWK/oUidXlTN5idPkJpRqELHrf7d4Bu7h4eHRpTBXqnT+bmN8fNw+/fTTN+16Hh4eHv814DOf+cwr1toHN7d7Bu7h4eHRpfAvcA8PD48uhX+Be3h4eHQp/Avcw8PDo0txU42YxpglAGUAy1c79zbHILp7Dt0+fqD759Dt4we6fw7dNP5Ja+3Q5sab+gIHAGPMy9tZU7sJ3T6Hbh8/0P1z6PbxA90/h24fP+BVKB4eHh5dC/8C9/Dw8OhS3IoX+OduwTXfbXT7HLp9/ED3z6Hbxw90/xy6ffw3Xwfu4eHh4fHuwKtQPDw8PLoUN/UFbox53Bhz0hhz2hjz6Zt57RuBMWa3MeZbYFqDaQAABHRJREFUxpgTxphjxphf5fZ+Y8wzxpi3+f++Wz3WK4GLUr9qjPkG/73XGPMCj/8PjDHXUcTp5sMY02uM+Yox5i2+F4914T34H3kPvWmM+aIxJnk73wdjzO8ZYxaNMW+qtm3X3BD+T36uXzfGPHDrRi7YYQ7/hvfR68aY/+yqjfGxX+c5nDTGfOTWjPr6cNNe4FzR598D+CiAOwF8whhz5826/g2iBeCfW2uPgOqA/gqP+dMAnrXWHgTwLP99O+NXQWXwHP41gH/H418D8KlbMqprx/8B4M+stYcBHAXNpWvugTFmAsA/BfCgtfZuAAGAj+P2vg+/D+DxTW07rflHARzkf08D+OxNGuPV8PvYOodnANxtrb0XwCkAvw4A/Fx/HMBd/J3/m99ZtzVuJgN/GMBpa+1Za20DwJcAPHkTr3/dsNbOWWt/yJ+LoBfHBGjcn+fTPg/gY7dmhFeHMWYXgJ8B8B/5bwPgQwC+wqfc7uPPA/gJcMk+a23DWruOLroHjCiAlDEmCiANYA638X2w1n4HwOqm5p3W/EkA/68l/ABU8HwMtxjbzcFa+xdciB0AfgAqyA7QHL5kra1ba88BOI0uqDh2M1/gEwBm1N8Xua0rYIyZApWWewHAiLV2DqCXPIDhWzeyq+J3APzPQFguewDAutrEt/t92AdgCcD/w2qg/2iMyaCL7oG19hKA3wIwDXpxbwB4Bd11H4Cd17xbn+1/COBP+XNXzuFmvsC3KzfRFS4wxpgsgK8C+GfW2sKtHs+1whjzswAWrbWv6OZtTr2d70MUwAMAPmutvR+UiuG2VZdsB9YVPwlgL4BxABmQ2mEzbuf7cCV0256CMeY3QCrSL7imbU67recA3NwX+EUAu9XfuwDM3sTr3xCMMTHQy/sL1to/4uYFJyLy/4u3anxXwfsA/Jwx5jxIZfUhECPvZVEeuP3vw0UAF621L/DfXwG90LvlHgDAhwGcs9YuWWubAP4IwHvRXfcB2HnNu+rZNsY8BeBnAfySFT/qrpqDw818gb8E4CBb3uMgg8HXb+L1rxusL/5dACestb+tDn0dwFP8+SkAX7vZY7sWWGt/3Vq7y1o7BVrvb1prfwnAtwD8Ap92244fAKy18wBmjDGuOOdPAjiOLrkHjGkAjxpj0ryn3By65j4wdlrzrwP4JHujPApgw6labjcYYx4H8GsAfs5aW1GHvg7g48aYhDFmL8gg++KtGON1wVp70/4BeAJk+T0D4Ddu5rVvcLw/BhKjXgfwI/73BEiP/CyAt/n//ls91muYywcAfIM/7wNtztMA/hBA4laP7ypjvw/Ay3wf/hhAX7fdAwCfAfAWgDcB/CcAidv5PgD4Ikhf3wSx00/ttOYg9cO/5+f6DZC3ze06h9MgXbd7nv+DOv83eA4nAXz0Vo//Wv75SEwPDw+PLoWPxPTw8PDoUvgXuIeHh0eXwr/APTw8PLoU/gXu4eHh0aXwL3APDw+PLoV/gXt4eHh0KfwL3MPDw6NL4V/gHh4eHl2K/x+CYtyojNHkDwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"grog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "# Let's see some of the images.\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Un-normalize (???)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "# Let's get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show the images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(\" \".join(\"%5s\" % classes[labels[j]] for j in range(4)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Define a Convolutional Neural Network\n",
    "We will use the architecture presented above, modified to take the correct number of channels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Define a Loss function and optimizer\n",
    "For this example, we will be using a Classification Cross-Entropy loss and SGD with momentum."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Train the network\n",
    "We will now loop over our data iterator and feed the inputs to the network, and optimize."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1,  2000] loss: 2.273\n",
      "[1,  4000] loss: 1.905\n",
      "[1,  6000] loss: 1.661\n",
      "[1,  8000] loss: 1.558\n",
      "[1, 10000] loss: 1.519\n",
      "[1, 12000] loss: 1.475\n",
      "[2,  2000] loss: 1.399\n",
      "[2,  4000] loss: 1.354\n",
      "[2,  6000] loss: 1.304\n",
      "[2,  8000] loss: 1.312\n",
      "[2, 10000] loss: 1.283\n",
      "[2, 12000] loss: 1.268\n",
      "Finished training.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for epoch in range(2):  # iterate over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches (what are these anyways??)\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished training.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}